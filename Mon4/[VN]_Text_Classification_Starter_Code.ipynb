{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AkEoCKaHdpj"
      },
      "source": [
        "\n",
        "Trong notebook này, chúng ta sẽ thử quy trình lập trình RNN với Keras để phân loại các câu văn bản.\n",
        "\n",
        "I.   **Trước tiên**, chúng ta sẽ nhập các thư viện hữu ích.\n",
        "\n",
        "II.   **Sau đó**, chúng ta sẽ load dữ liệu và tạo ma trận word embedding bằng Glove.\n",
        "\n",
        "III.  **Chúng ta sẽ thử một mô hình RNN đơn giản** rồi đánh giá chất lượng của nó.\n",
        "\n",
        "IV. Cuối cùng, chúng ta sẽ sử dụng các kỹ thuật để gia tăng độ chính xác của mô hình."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xY_w9I1cZni"
      },
      "source": [
        "**Task 1:** Thiết lập Fre GPU trong notebook này."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9y_XluJ0lie",
        "outputId": "2e048d71-3a8a-4bda-e884-68d89bfe4f08"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-f0f54757-3dc9-16c4-0dfe-9e01c3648620)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4iAL0E0ciDS"
      },
      "source": [
        "## Gắn Google Drive cục bộ\n",
        "**Task 2:** Gắn Google vào Google Colab Driver.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8iz8Rp8H5pG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c071403f-8906-45f3-ea4d-edfac9839bff"
      },
      "source": [
        "## VIẾT CODE cho task 2 ở đây:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeAakuO9cD5s"
      },
      "source": [
        "# I. Nhập tất cả các thư viện hữu ích."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWgEP6KSHmV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86e7cf1-a22b-4742-a79d-fa48c103d93f"
      },
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import tensorflow.keras\n",
        "import datetime\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras.optimizers as Optimizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from sklearn.metrics import confusion_matrix as CM\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plot\n",
        "import seaborn as sn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVKAU6gAAs-u",
        "outputId": "c2d9e650-91d8-4557-d42f-68733e30dc6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/612.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvFTfBIscRwC"
      },
      "source": [
        "**Task 3**: Copy tập dữ liệu từ Google Drive vào Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzzQsanZIZfg"
      },
      "source": [
        "## VIẾT CODE cho task 3 ở đây:\n",
        "data_dir = '/content/drive/MyDrive/FUNIX/MON4/ASM2/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_GxFMl7dFJ-"
      },
      "source": [
        "# II. Load dữ liệu.\n",
        "\n",
        "## Về tập dữ liệu.\n",
        "Câu hỏi không hợp lệ là những câu hỏi nhằm đưa ra một tuyên bố thay vì tìm kiếm những câu trả lời hữu ích. Một số đặc điểm cho thấy câu hỏi không hợp lệ gồm:\n",
        "\n",
        "* Có giọng điệu không trung lập.\n",
        "* Có tính chê bai hoặc kích động.\n",
        "* Không có căn cứ thực tế.\n",
        "* Sử dụng nội dung khiêu dâm (loạn luân, thú tính, ấu dâm) để gây sốc, không phải để tìm kiếm câu trả lời xác thực.\n",
        "\n",
        "Dữ liệu bao gồm câu hỏi đã đề ra và liệu nó có được xác định là không hợp lệ hay không (target = 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9HhWwT-gpuN"
      },
      "source": [
        "**Task 4**: Load tập dữ liệu.\n",
        "* Load dữ liệu từ file CSV.\n",
        "* Xóa tất cả các hàng có giá trị NA.\n",
        "* Chia dữ liệu thành 3 tập: Tập huấn luyện, tập kiểm định và tập kiểm tra (0.9/0.05/0.05, random_seed = 9) với cùng một tỷ lệ số dữ liệu giữa mỗi lớp.\n",
        "* In ra mô tả của tập dữ liệu này.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9HMbZrqK1Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feee3f22-e23e-47af-a2b7-6731f20c879a"
      },
      "source": [
        "def load_data(data_link):\n",
        "    '''\n",
        "    input: data link.\n",
        "    output:\n",
        "        train_set, validation_set và test_set(0.95/0.05/0.05) mà không có các giá trị NA.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 4 ở đây:\n",
        "    file_name = data_dir + data_link\n",
        "    data = pd.read_csv(file_name)\n",
        "    data.rename(columns={'target':'label'}, inplace=True)\n",
        "    data = data.dropna()\n",
        "    train, validation, test = np.split(data.sample(frac=1),[int(0.9*len(data)), int(0.95*len(data))])\n",
        "\n",
        "    return train, validation, test\n",
        "np.random.seed(9)\n",
        "train_set, validation_set, test_set = load_data('train.csv')\n",
        "print(train_set['label'].describe())\n",
        "print(validation_set['label'].describe())\n",
        "print(test_set['label'].describe())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    1.175509e+06\n",
            "mean     6.190340e-02\n",
            "std      2.409801e-01\n",
            "min      0.000000e+00\n",
            "25%      0.000000e+00\n",
            "50%      0.000000e+00\n",
            "75%      0.000000e+00\n",
            "max      1.000000e+00\n",
            "Name: label, dtype: float64\n",
            "count    65306.000000\n",
            "mean         0.062261\n",
            "std          0.241630\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%          0.000000\n",
            "max          1.000000\n",
            "Name: label, dtype: float64\n",
            "count    65307.000000\n",
            "mean         0.060882\n",
            "std          0.239115\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%          0.000000\n",
            "max          1.000000\n",
            "Name: label, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIcOnRkbqofC"
      },
      "source": [
        "# Mã hóa dữ liệu văn bản.\n",
        "Hãy khai báo một số tham số cơ bản trước:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F3_zcCjHwzm"
      },
      "source": [
        "embed_size = 50 # mỗi vectơ từ lớn bao nhiêu\n",
        "max_features = 20000 # cần sử dụng bao nhiêu từ duy nhất (tức là số hàng trong vectơ embedding)\n",
        "max_len = 50 # sử dụng số từ tối đa trong câu hỏi\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT8m71iixjxt"
      },
      "source": [
        "**Task 5:** Mã hóa tập dữ liệu bằng Tokenizer và vectơ biểu diễn one-hot.\n",
        "* Mã hóa văn bản (cột question_text) bằng cách chuyển từng question text thành danh sách chỉ mục từ bằng [Tokenizer](https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do) với **max_features** và tất cả các câu văn bản từ tập huấn luyện và tập kiểm định.\n",
        "* Chuyển từng danh sách chỉ mục từ thành độ dài như nhau - **max_len** (có cắt tỉa hoặc đệm nếu cần) bằng cách sử dụng [pad_sequences](https://keras.io/preprocessing/sequence/).\n",
        "* Mã hóa nhãn (cột nhãn) bằng cách sử dụng hàm [to_categorical](https://keras.io/utils/) trong Keras."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = train_set['question_text']\n",
        "validation_sentences = validation_set['question_text']\n",
        "test_sentences = test_set['question_text']\n",
        "train_labels = train_set['label']\n",
        "validation_labels = validation_set['label']\n",
        "test_labels = test_set['label']"
      ],
      "metadata": {
        "id": "o4FaJ2FiMvwp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1MZKNs4xmfP"
      },
      "source": [
        "def encoding_textdata(train_set, validation_set, test_set, max_features, max_len):\n",
        "    '''\n",
        "    Input:\n",
        "    - Train/validation/test dataset.\n",
        "    - max_features, max_len.\n",
        "    Output:\n",
        "    - X train/validation/test, y train/validation/test.\n",
        "    - Tokenizer.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 5 ở đây:\n",
        "\n",
        "    tokenizer = Tokenizer(num_words = max_features)\n",
        "    tokenizer.fit_on_texts(list(train_sentences))\n",
        "\n",
        "    X_tr = tokenizer.texts_to_sequences(train_sentences)\n",
        "    X_va = tokenizer.texts_to_sequences(validation_sentences)\n",
        "    X_te = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "    X_tr = pad_sequences(X_tr, maxlen=max_len)\n",
        "    X_va = pad_sequences(X_va, maxlen=max_len)\n",
        "    X_te = pad_sequences(X_te, maxlen=max_len)\n",
        "\n",
        "    y_tr = to_categorical(train_labels)\n",
        "    y_va = to_categorical(validation_labels)\n",
        "    y_te = to_categorical(test_labels)\n",
        "\n",
        "    return (X_tr, y_tr), (X_va, y_va), (X_te, y_te), tokenizer\n",
        "\n",
        "(X_tr, y_tr), (X_va, y_va), (X_te, y_te), tokenizer = encoding_textdata(train_set, validation_set, test_set, max_features, max_len)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kpG-p30WUcc"
      },
      "source": [
        "**Task 6**: Tạo ma trận word embedding.\n",
        "* Đầu tiên, hãy viết một hàm để load [GloVe dictionary.](https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db)\n",
        "* Sau đó, tạo ma trận word embedding bằng GloVe dictionary với các tham số sau:\n",
        "    - Shape của ma trận word embedding: (Number of word, embed_size).\n",
        "    - Embed size: 50.\n",
        "    - Number of words: Tối thiểu của (max_features, len(word_index)), trong khi word_index là dictionary của từ chứa trong tokenizer.\n",
        "    - Nếu một từ xuất hiện trong GloVe dictionary, chúng ta nên lấy giá trị khởi tạo của nó như trong GloVe dictionary. Nếu không, hãy lấy một giá trị ngẫu nhiên bình thường với mean và std làm mean và std của giá trị GloVe dictionary.\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47s8-SncWT3V"
      },
      "source": [
        "\n",
        "def get_coefs(word,*arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "def get_GloVe_dict(GloVe_link):\n",
        "    '''\n",
        "    input: GloVe link.\n",
        "    output: GloVe dictionary.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 6 ở đây:\n",
        "    link = '/content/drive/MyDrive/FUNIX/MON4/ASM2/' + GloVe_link\n",
        "    embeddings_dict = {}\n",
        "    with open(link, 'r', encoding='utf-8') as f:\n",
        "      for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], 'float32')\n",
        "        embeddings_dict[word] = vector\n",
        "    return embeddings_dict\n",
        "GloVe_link = 'glove.6B.50d.txt'\n",
        "GloVe_dict = get_GloVe_dict(GloVe_link)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXRyFSLtr4_k"
      },
      "source": [
        "def create_embedding_matrix(GloVe_dict, tokenizer, max_features):\n",
        "    '''\n",
        "    input: GloVe dictionaray, tokenizer từ tập huấn luyện và tập kiểm định, số lượng đặc trưng tối đa.\n",
        "    output: Word embedding matrix.\n",
        "    '''\n",
        "\n",
        "    ## VIẾT CODE cho task 6 ở đây:\n",
        "    all_embs = np.stack(list(GloVe_dict.values()))\n",
        "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "    number_of_words = min(max_features, (len(tokenizer.word_index)+1))\n",
        "    #number_of_words = len(tokenizer.word_index)\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (number_of_words, embed_size))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "      i -= 1\n",
        "      embedding_value = GloVe_dict.get(word)\n",
        "      if embedding_value is not None and i < number_of_words:\n",
        "        embedding_matrix[i] = embedding_value\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_matrix = create_embedding_matrix(GloVe_dict, tokenizer, max_features)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWybjdQkqWrg"
      },
      "source": [
        "# III. Lập mô hình\n",
        "Chúng ta cần hoàn thành một số bước:\n",
        "\n",
        "Xây dựng mô hình.\n",
        "\n",
        "Biên dịch mô hình.\n",
        "\n",
        "Huấn luyện/khớp dữ liệu với mô hình.\n",
        "\n",
        "Đánh giá mô hình trên tập kiểm tra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6AMfqQkqcET"
      },
      "source": [
        "## Xây dựng mô hình\n",
        "**Task 7:** Chúng ta có thể xây dựng một mô hình dễ dàng gồm các layer khác nhau như:\n",
        "* Layer [Embedding](https://keras.io/layers/embeddings/) với max_features, embed_size và embedding_matrix.\n",
        "* [Bidirectional LSTM layer](https://keras.io/examples/nlp/bidirectional_lstm_imdb/?fbclid=IwAR3fEd6aWyeIDEhZSspjtCRiP0c0Jnz5-XdnUHQYwX8Tp8k9Ni4I8Q5tP9o) với số lượng trạng thái ẩn = 50, dropout_rate = 0.1 và recurrent_dropout_rate = 0.1.\n",
        "* GlobalMaxPool1D.\n",
        "* Dense với số nút = 50, activation = 'relu'.\n",
        "* Dropout với rate = 0.1.\n",
        "* Final dense với số nút = số class, activation = 'sigmoid'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7_eizWaqi_7"
      },
      "source": [
        "def create_model(max_len, max_features, embed_size):\n",
        "    '''\n",
        "    input: max_len, max_features, embed_size\n",
        "    output: model.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 7 ở đây:\n",
        "    inputs = Input(shape=(max_len, ))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inputs)\n",
        "    x = Bidirectional(LSTM(50,return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
        "    x = GlobalMaxPool1D()(x)\n",
        "    x = Dense(50, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    outputs = Dense(2, activation='sigmoid')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_model(max_len, max_features, embed_size)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWcBKhzMux9Z"
      },
      "source": [
        "**Task 8:** Biên dịch mô hình và thiết lập callback. Sau đó in ra model summary.\n",
        "* [Biên dịch](https://keras.io/models/model/#compile) mô hình với Adam Optimizer, lr = 1e-2, loss phù hợp cho bài toán phân loại nhị phân và [\"F1-score\"](https://github.com/tensorflow/addons/issues/825) là phép đo.\n",
        "* In ra model summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9l8EbG0ur1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86cdd125-626a-4c1a-b590-471d7f876e27"
      },
      "source": [
        "def optimize(model):\n",
        "    '''\n",
        "    Input:\n",
        "        Mô hình.\n",
        "    Return:\n",
        "        Mô hình đã biên dịch.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 8 ở đây:\n",
        "    model.compile(loss = 'binary_crossentropy',\n",
        "                  optimizer = optimizers.Adam(learning_rate=1e-2),\n",
        "                  metrics = ['F1-score'])\n",
        "    return model\n",
        "\n",
        "model = optimize(model)\n",
        "print(model.summary())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 50)]              0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 50, 50)            1000000   \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 50, 100)           40400     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Gl  (None, 100)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1045552 (3.99 MB)\n",
            "Trainable params: 1045552 (3.99 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BlenccGzLVr"
      },
      "source": [
        "**Task 9**: Thiết lập callback.\n",
        "* Tạo [tensorboard callback](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks) để lưu logs.\n",
        "* Tạo [checkpoint callback](https://machinelearningmastery.com/check-point-deep-learning-models-keras/) để lưu checkpoint với độ chính xác tốt nhất sau mỗi epoch.\n",
        "* Tạo [ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau) callback với factor=0.3, patience=1 và \"Validation F1-score\" monitor.\n",
        "* Tạo [early stopping callback](https://keras.io/callbacks/#earlystopping) với patience=7, mode = 'max' và \"Validation F1-score\" monitor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6x6dteutin0"
      },
      "source": [
        "def callback_model(checkpoint_name, logs_name):\n",
        "    '''\n",
        "    Input:\n",
        "        Checkpoint name, logs name tốt nhất.\n",
        "    Return:\n",
        "        Callback list có chứa tensorboard callback và checkpoint callback.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 9 ở đây:\n",
        "    logdir = os.path.join(logs_name, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    callbacks_list = [TensorBoard(log_dir=logdir),\n",
        "                      ModelCheckpoint(filepath=checkpoint_name, monitor='val_accuracy', save_best_only=True, mode='max'),\n",
        "                      tensorflow.keras.callbacks.ReduceLROnPlateau(factor=0.3, patience=1, monitor='Validation F1-score'),\n",
        "                      tensorflow.keras.callbacks.EarlyStopping(patience=7, mode='max', monitor='Validation F1-score')\n",
        "                      ]\n",
        "\n",
        "    return callbacks_list\n",
        "\n",
        "checkpoint_name = 'weights.best.hdf5'\n",
        "logs_name = 'training_logs'\n",
        "callbacks_list = callback_model(checkpoint_name, logs_name)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHTwh8OyvGqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68af506-b59f-499a-9932-3f31627c2334"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 50)]              0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 50, 50)            1000000   \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 50, 100)           40400     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Gl  (None, 100)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1045552 (3.99 MB)\n",
            "Trainable params: 1045552 (3.99 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nDCsHAC2HwW"
      },
      "source": [
        "**Task 10:** Huấn luyện mô hình.\n",
        "\n",
        "* Huấn luyện mô hình với 20 epoch với batch_size = 4096.\n",
        "* Trả về mô hình có trọng số checkpoint tốt nhất.\n",
        "\n",
        "*Gợi ý*: Trước tiên hãy khớp mô hình, sau đó reload mô hình (hàm load_model) với trọng số checkpoint tốt nhất."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xttwiHh4u0ES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "1bfcbed2-c1e9-405d-9499-be5a56874de9"
      },
      "source": [
        "def train_model(model, callbacks_list):\n",
        "    '''\n",
        "    Input:\n",
        "        Mô hình và callback list,\n",
        "    Return:\n",
        "        Mô hình với trọng số checkpoint tốt nhất.\n",
        "    '''\n",
        "    ## VIẾT CODE cho task 10 ở đây:\n",
        "    epochs = 20\n",
        "    batch_size = 4096\n",
        "    model_1 = model.fit(X_tr, y_tr,\n",
        "                        batch_size = batch_size,\n",
        "                        epochs = epochs,\n",
        "                        validation_data = (X_va, y_va),\n",
        "                        callbacks = callbacks_list)\n",
        "    #model = load_model('weights.best.hdf5')\n",
        "\n",
        "    return model\n",
        "\n",
        "model = train_model(model, callbacks_list)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-3bca20676f21>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-3bca20676f21>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, callbacks_list)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     model_1 = model.fit(X_tr, y_tr,\n\u001b[0m\u001b[1;32m     12\u001b[0m                         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsG02Ao07Mc-"
      },
      "source": [
        "**Task 11:** Hiển thị tensorboard trong notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpBk-EKZ2Ut7"
      },
      "source": [
        "## VIẾT CODE cho task 11 ở đây:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z1ed1CY8Rxh"
      },
      "source": [
        "**Task 12:** Dự đoán trên tập kiểm tra.\n",
        "\n",
        "* Hoàn thành hàm get_prediction_classes.\n",
        "* In ra precision, recall và F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHTjBLZYvx26"
      },
      "source": [
        "def get_prediction_classes(model, X, y):\n",
        "    ## VIẾT CODE cho task 12 ở đây:\n",
        "    '''\n",
        "    Input:\n",
        "        Mô hình và tập dữ liệu dự đoán.\n",
        "    Return:\n",
        "        Prediction list và groundtrurth list với predicted classes.\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "    return predictions, groundtruths\n",
        "\n",
        "\n",
        "test_predictions, test_groundtruths = get_prediction_classes(model,  X_te, y_te)\n",
        "print(precision_score(test_predictions, test_groundtruths))\n",
        "print(recall_score(test_predictions, test_groundtruths))\n",
        "print(f1_score(test_predictions, test_groundtruths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJwQahjp8hZs"
      },
      "source": [
        "**Task 13:** Thực hiện kết quả dự đoán trên tập kiểm tra bằng cách sử dụng ma trận nhầm lẫn. Hãy nhớ hiển thị tên lớp trong ma trận nhầm lẫn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KKAmOGvv2Be"
      },
      "source": [
        "def plot_confusion_matrix(predictions, groundtruth, class_names):\n",
        "    ## VIẾT CODE cho task 13 ở đây:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plot.show()\n",
        "class_names = ['valid', 'invalid']\n",
        "plot_confusion_matrix(test_predictions, test_groundtruths, class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGmUAFDi87Z6"
      },
      "source": [
        "**Task 14**: Tinh chỉnh mô hình - tinh chỉnh mô hình bằng cách sử dụng một số phương pháp sau:\n",
        "* Tăng tối đa epoch, thay đổi batch size.\n",
        "* Thay thế LSTM bằng các nút GRU và kiểm tra xem nó có thay đổi gì không.\n",
        "* Thêm một layer LSTM/GRU khác hoặc thay thế nó bằng mô-đun Attention/Transformers, xem có cải thiện gì không.\n",
        "* Thử với Dense layer (add/# units/...).\n",
        "* Tìm các quy tắc tiền xử lý mà bạn có thể thêm để cải thiện chất lượng dữ liệu.\n",
        "* Find another GloVe dictionary. Tìm một GloVe dictionary khác.\n",
        "Yêu cầu: F1 score phải tăng thêm 2-3%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELLyczmROE8J"
      },
      "source": [
        "## VIẾT CODE cho task 14 ở đây:"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}